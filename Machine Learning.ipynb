{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c56c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hy')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/TRYMORE/Desktop/DataSets/creditdata.csv\")\n",
    "print('Columns:',df.columns)\n",
    "\n",
    "#Separate continuos columns\n",
    "num_cols = df.select_dtypes(include = ['number']).columns\n",
    "print('Numerical Columns:', num_cols)\n",
    "\n",
    "#Select categorical colums\n",
    "cat_cols = df.select_dtypes(include = ['object', 'category']).columns\n",
    "print('Categorical Columns:', cat_cols)\n",
    "\n",
    "#Fill missing values for numerical variables\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].mean())\n",
    "\n",
    "#Fill missing values for categorical variables\n",
    "df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode())\n",
    "\n",
    "#Fix data types once \n",
    "df = df.convert_dtypes()\n",
    "\n",
    "#Drop column Customer ID since its not a variable\n",
    "df.drop(columns = ['Customer_ID'],inplace = True)\n",
    "\n",
    "#Label encording ordinal variables\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder as ln\n",
    "df['Level_of_Education'] = ln().fit_transform(df['Level_of_Education'])\n",
    "df['Residence_Area'] = ln().fit_transform(df['Residence_Area'])\n",
    "df['Tenure'] = ln().fit_transform(df['Tenure'])\n",
    "\n",
    "#Norminal  variables Target encoding\n",
    "#Install it with pip install category_encoders\n",
    "import category_encoders as ce\n",
    "#List the norminal variables\n",
    "nominal_vars = ['Gender', 'Marital_Status', 'Employment_Status','Home_Ownership','Other_Solar_Product_purchase_on_installments']\n",
    "#Initialize the encoder\n",
    "target_encoder = ce.TargetEncoder(cols=nominal_vars)\n",
    "#Fit and transform the data\n",
    "df[nominal_vars] = target_encoder.fit_transform(df[nominal_vars], df['DefaultStatus'])\n",
    "\n",
    "#Define the continuous variables\n",
    "num_vars = ['Age', 'Number_of_Dependants', 'Product_Quantity', 'Total_Amount']\n",
    "\n",
    "#Standard Scaler--Best for algorithms that assume normality eg linear models, SVM, Logistic Reg...it keeps outliers and centers data \n",
    "from sklearn.preprocessing import StandardScaler as stds\n",
    "scaler = stds()\n",
    "df[num_vars] = scaler.fit_transform(df[num_vars])\n",
    "\n",
    "#MinMax Scaler--For algorithms that rely on distances or are sensitive to e scale eg KNN, Neural nets(nb use it when you dont have extreme outliers)\n",
    "#from sklearn.preprocessing import MinMaxScaler as mms\n",
    "#scaler = mms()\n",
    "df[num_vars] = scaler.fit_transform(df[num_vars])\n",
    "\n",
    "#Use Quantile transformer--robust for handling both scale and outliers\n",
    "#from sklearn.preprocessing import QuantileTransformer as qt\n",
    "#scaler = qt(n_quantiles=100)\n",
    "#df[num_vars] = scaler.fit_transform(df[num_vars])\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "x = df.drop('DefaultStatus', axis = 1)\n",
    "y = df['DefaultStatus']\n",
    "x_train, x_test, y_train, y_test = tts(x, y, test_size = 0.3, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###SUPERVISED MACHINE LEARNING METHODS\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "model = lg(class_weight={0:1, 1:2}, max_iter=1000)\n",
    "model.fit( x_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "\n",
    "#Odds Ratios\n",
    "import numpy as np\n",
    "odds_ratios = pd.Series(np.exp(model.coef_[0]),\n",
    "index = x.columns)\n",
    "print(odds_ratios.sort_values(ascending = False))\n",
    "\n",
    "#Baseline log_odds\n",
    "print('Intercept (log-odds):',\n",
    "      model.intercept_[0])\n",
    "print('Intercept (odds):',\n",
    "      np.exp(model.intercept_[0]))\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model.predict(x_test)\n",
    "probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'Logistic Regression')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "model1 = dt(random_state = 42)\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "predictions = model1.predict(x_test)\n",
    "probs = model1.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'Decision Tree')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "score = acs(y_test, predictions)\n",
    "\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-NEAREST NEIGHBORS\n",
    "from sklearn.neighbors import KNeighborsClassifier as kn\n",
    "model2 = kn(n_neighbors = 5)\n",
    "model2.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model2.predict(x_test)\n",
    "probs = model2.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'KNN')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bace96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as ld\n",
    "model3 = ld()\n",
    "model3.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model3.predict(x_test)\n",
    "probs = model3.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'LDA')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadratic Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as qd\n",
    "model4 = qd()\n",
    "model4.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model4.predict(x_test)\n",
    "probs = model4.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'QDA')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC as svm\n",
    "model5 = svm(probability = True)\n",
    "model5.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model5.predict(x_test)\n",
    "probs = model5.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'SVM')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "model6 = mlp(hidden_layer_sizes=(100, 50), activation='tanh', solver='adam', random_state=42, max_iter=300)\n",
    "model6.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model6.predict(x_test)\n",
    "probs = model6.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'MLP')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ESEMBLE LEARNING\n",
    "#Bagging\n",
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "model10 = rf(n_estimators=100, random_state=42)\n",
    "model10.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model10.predict(x_test)\n",
    "probs = model10.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'rf')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOTHER METHOD OF BAGGING(THE MANUALY ONE)\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier as bc\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "\n",
    "#Base estimator\n",
    "base_dt = dt()\n",
    "\n",
    "#Bagging Classifier\n",
    "model11 = bc(estimator=base_dt, n_estimators=100, random_state=42)\n",
    "model11.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model11.predict(x_test)\n",
    "probs = model11.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'Bagging Classifier')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BAGGING(USING LOGISTIC)\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier as bc\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "\n",
    "#Base estimator\n",
    "base_dt = lg()\n",
    "\n",
    "#Bagging Classifier\n",
    "model12 = bc(estimator=base_dt, n_estimators=100, random_state=42)\n",
    "model12.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model12.predict(x_test)\n",
    "probs = model12.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'Bagging ClassifierLOG')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting\n",
    "#Gradient Boosting\n",
    "\n",
    "#BAGGING(USING LOGISTIC)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gb\n",
    "\n",
    "model13 = gb(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model13.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model13.predict(x_test)\n",
    "probs = model13.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'GB')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting\n",
    "#ADABOOST\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier as ad\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "\n",
    "#Base weak learner\n",
    "base_model = dt(max_depth = 1)\n",
    "\n",
    "\n",
    "#AdaBoost Classifier\n",
    "model14 = ad(estimator = base_model, n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "model14.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "predictions = model14.predict(x_test)\n",
    "probs = model14.predict_proba(x_test)[:, 1]\n",
    "\n",
    "#Classification report\n",
    "print('\\nClassification Report:')\n",
    "print('Report:',classification_report(y_test, predictions))\n",
    "\n",
    "#Confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print('Confusion:', confusion_matrix(y_test, predictions))\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "plt.plot(fpr, tpr,\n",
    "         label = 'ADA')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "score = acs(y_test, predictions)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta Estimators\n",
    "\n",
    "#Voting Classifier(trains many models and average(hardvoting)or use majority voting)\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "from sklearn.ensemble import VotingClassifier as vc\n",
    "from sklearn.datasets import make_classification as mc\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = model4\n",
    "clf2 = knc(n_neighbors = 5).fit(x_train, y_train)\n",
    "clf3 = vc(estimators = [('clf1', clf1), ('clf2', clf2)],\n",
    "          voting = 'soft',\n",
    "          weights = (0.5, 0.5))\n",
    "\n",
    "clf3.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which base model is better\n",
    "\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "\n",
    "predLR = model6.predict(x_test)\n",
    "predKN = clf2.predict(x_test)\n",
    "predVC = clf3.predict(x_test)\n",
    "\n",
    "scoreLR = acs(y_test, predLR)\n",
    "scoreKN = acs(y_test, predKN)\n",
    "scoreVC = acs(y_test, predVC)\n",
    "print('Accuracy of QD:', scoreLR)\n",
    "print('Accuracy of KN:', scoreKN)\n",
    "print('Accuracy of VC:', scoreVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ca8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the models so that the next time we use them, we wont train again, but we rather only load and use them\n",
    "import joblib\n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(model1, 'model1.pkl')\n",
    "joblib.dump(model2, 'model2.pkl')\n",
    "joblib.dump(model3, 'model3.pkl')\n",
    "joblib.dump(model4, 'model4.pkl')\n",
    "joblib.dump(model5, 'model5.pkl')\n",
    "joblib.dump(model6, 'model6.pkl')\n",
    "\n",
    "joblib.dump(model10, 'model10.pkl')\n",
    "joblib.dump(model11, 'model11.pkl')\n",
    "joblib.dump(model12, 'model12.pkl')\n",
    "joblib.dump(model13, 'model13.pkl')\n",
    "joblib.dump(model14, 'model14.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35727489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and using the trained mode...an example\n",
    "import joblib\n",
    "import pickle\n",
    "import streamlit as st\n",
    "LR = joblib.load('model.pkl')\n",
    "\n",
    "def main():\n",
    "    st.title('Credit Risk Prediction Model')\n",
    "\n",
    "#Input Variables\n",
    "#User inputs\n",
    "age = st.number_input(\"Age\", min_value=18, max_value=100, value=30)\n",
    "marital_status = st.selectbox(\"Marital Status\", ['Single', 'Married', 'Divorced'])  # example categories\n",
    "employment_status = st.selectbox(\"Employment Status\", ['Employed', 'Unemployed'])\n",
    "level_of_education = st.selectbox(\"Level of Education\", [0, 1, 2])  # ordinal values you used during encoding\n",
    "residence_area = st.selectbox(\"Residence Area\", [0, 1, 2])\n",
    "home_ownership = st.selectbox(\"Home Ownership\", ['Yes', 'No'])\n",
    "dependents = st.number_input(\"Number of Dependants\", min_value=0)\n",
    "product_quantity = st.number_input(\"Product Quantity\", min_value=0)\n",
    "total_amount = st.number_input(\"Total Amount\", min_value=0.0)\n",
    "\n",
    "#Prepare input\n",
    "input_df = pd.DataFrame({\n",
    "    'Age': [age],\n",
    "    'Marital_Status': [marital_status],\n",
    "    'Employment_Status': [employment_status],\n",
    "    'Level_of_Education': [level_of_education],\n",
    "    'Residence_Area': [residence_area],\n",
    "    'Home_Ownership': [home_ownership],\n",
    "    'Number_of_Dependants': [dependents],\n",
    "    'Product_Quantity': [product_quantity],\n",
    "    'Total_Amount': [total_amount]\n",
    "})\n",
    "\n",
    "#Predict\n",
    "if st.button(\"Predict\"):\n",
    "    prediction = model.predict(input_df)\n",
    "    st.success(f\"Prediction: {'Default' if prediction[0] == 1 else 'No Default'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4795c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##UNSUPERVISED MACHINE LEARNING METHODS\n",
    "\n",
    "# K-Means Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Now the response variable is not allowed so drop it\n",
    "x = df.drop('DefaultStatus', axis = 1)\n",
    "\n",
    "#With three clusters\n",
    "kmeans = KMeans(n_clusters = 3, random_state = 42)\n",
    "kmeans.fit(x)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "#Add cluster labels to e DataFrame\n",
    "x['Cluster'] = labels\n",
    "\n",
    "#Visualize the clusters with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(x.drop('Cluster', axis = 1))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x_pca[:, 0], x_pca[:, 1], c = x['Cluster'], cmap = 'viridis')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
